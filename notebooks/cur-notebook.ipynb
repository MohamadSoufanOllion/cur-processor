{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "\n",
    "session = boto3.Session()\n",
    "sts_client = session.client('sts')\n",
    "identity = sts_client.get_caller_identity()\n",
    "identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from polars import col\n",
    "from itables import init_notebook_mode\n",
    "\n",
    "pl.Config.set_tbl_rows(25)\n",
    "pl.Config.set_fmt_str_lengths(255)\n",
    "\n",
    "init_notebook_mode(all_interactive=False)\n",
    "df = pl.read_parquet('./hearst-sandbox-dec-cur.snappy.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_arn(arn: str) -> list:\n",
    "    \"\"\"\n",
    "    Splits the ARN into its components and validates basic structure.\n",
    "\n",
    "    Parameters:\n",
    "    - arn (str): The ARN to split and validate.\n",
    "\n",
    "    Returns:\n",
    "    - list: Components of the ARN.\n",
    "    \"\"\"\n",
    "    if not arn.startswith(\"arn:\"):\n",
    "        raise ValueError(\"Invalid ARN: must start with 'arn:'\")\n",
    "    \n",
    "    arn_parts = arn.split(\":\")\n",
    "    \n",
    "    if len(arn_parts) < 6:\n",
    "        raise ValueError(\"Invalid ARN format.\")\n",
    "    \n",
    "    return arn_parts\n",
    "\n",
    "def extract_resource_id_from_arn(arn: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the resource ID from a given AWS ARN string if applicable.\n",
    "\n",
    "    Parameters:\n",
    "    - arn (str): The ARN from which to extract the resource ID.\n",
    "\n",
    "    Returns:\n",
    "    - str: The resource ID extracted from the ARN.\n",
    "    \"\"\"\n",
    "    arn_parts = split_arn(arn)\n",
    "    resource_part = arn_parts[5]\n",
    "\n",
    "    # Specific handling for ARNs where resource is not delimited\n",
    "    if arn.startswith(\"arn:aws:s3:::\"):\n",
    "        return resource_part  # Directly return the bucket name\n",
    "\n",
    "    # Handle case where the resource part might have specific format, e.g., \"resource-type/resource-id\"\n",
    "    resource_id = resource_part.split(\"/\")[-1]\n",
    "\n",
    "    return resource_id\n",
    "\n",
    "def is_non_arn_identifier(arn: str) -> bool:\n",
    "    \"\"\"\n",
    "    Determines if an ARN belongs to a resource typically shown as a non-ARN identifier in CUR.\n",
    "\n",
    "    Args:\n",
    "    - arn (str): The ARN string to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the resource is typically identified by a non-ARN ID in CUR, otherwise False.\n",
    "    \"\"\"\n",
    "    arn_parts = split_arn(arn)\n",
    "    resource_info = arn_parts[5]\n",
    "    resource_type = resource_info.split(\"/\")[0].lower()\n",
    "\n",
    "    # Include \"bucket\" to target S3 resources accurately\n",
    "    non_arn_resources = {\"instance\", \"vol\", \"snap\", \"db\", \"table\", \"bucket\", \"net\"}\n",
    "\n",
    "    return resource_type in non_arn_resources\n",
    "\n",
    "def extract_and_handle_resource_id(arn: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts and returns the resource ID from an ARN only if it is a known non-ARN resource type.\n",
    "\n",
    "    Args:\n",
    "    - arn (str): The ARN from which to possibly extract the resource ID.\n",
    "\n",
    "    Returns:\n",
    "    - str: The resource ID if applicable, otherwise returns the entire ARN.\n",
    "    \"\"\"\n",
    "    if is_non_arn_identifier(arn):\n",
    "        return extract_resource_id_from_arn(arn)\n",
    "    \n",
    "    return arn\n",
    "\n",
    "# Example usages\n",
    "arn1 = \"arn:aws:ec2:us-east-1:123456789012:instance/i-0abcdef1234567890\"\n",
    "arn2 = \"arn:aws:s3:::my-example-bucket\"\n",
    "\n",
    "resource_id1 = extract_and_handle_resource_id(arn1)\n",
    "resource_id2 = extract_and_handle_resource_id(arn2)\n",
    "\n",
    "print(f\"Resource ID 1: {resource_id1}\")  # Should extract and print instance ID\n",
    "print(f\"Resource ID 2: {resource_id2}\")  # Should print bucket name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate resource_ids which are not ARNs\n",
    "This will also test out joining them back with the tags triplet (just EC2 and one region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the non-ARN resources in EC2\n",
    "\n",
    "non_arn_df = df.filter(col(\"line_item_resource_id\").is_not_null() &\n",
    "                    col(\"product_region_code\").is_not_null() &\n",
    "                    col(\"line_item_product_code\").eq(\"AmazonEC2\") &\n",
    "                    ~col(\"line_item_resource_id\").str.starts_with(\"arn:aws:\") \n",
    "                    )\n",
    "\n",
    "\n",
    "derived_arn_df = non_arn_df.with_columns(\n",
    "    pl.when(col(\"line_item_resource_id\").str.starts_with(\"i-\"))\n",
    "    .then(\n",
    "        \"arn:aws:ec2:\" + col(\"product_region_code\") + \":\" + col(\"line_item_usage_account_id\") + \":instance/\" + col(\"line_item_resource_id\")\n",
    "    )\n",
    "    .when(col(\"line_item_resource_id\").str.starts_with(\"vol-\"))\n",
    "    .then(\n",
    "        \"arn:aws:ec2:\" + col(\"product_region_code\") + \":\" + col(\"line_item_usage_account_id\") + \":volume/\" + col(\"line_item_resource_id\")\n",
    "    )\n",
    "    .otherwise(col(\"line_item_resource_id\"))\n",
    "    .alias(\"ResourceARN\")  # Replace the column with the new one\n",
    ")\n",
    "\n",
    "derived_arn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique AWS resources\n",
    "not_null_resources_df = df.filter(pl.col('line_item_resource_id').is_not_null() & pl.col('product_region_code').is_not_null())\n",
    "# Select columns relevant for TCO calculation in addition to those for resources identification\n",
    "unique_resources_df = not_null_resources_df.select([\n",
    "    'line_item_resource_id', \n",
    "    'line_item_product_code', \n",
    "    'product_region_code', \n",
    "    'line_item_usage_account_id',\n",
    "    'resource_tags',\n",
    "\n",
    "    'line_item_blended_cost', \n",
    "    'line_item_blended_rate', \n",
    "\n",
    "    'line_item_unblended_cost',\n",
    "    'line_item_unblended_rate', \n",
    "\n",
    "    'savings_plan_savings_plan_effective_cost',  # or potential discount columns\n",
    "    'pricing_term'  # A potential column for identifying fixed vs variable costs\n",
    "])\n",
    "# unique_resources_df = unique_resources_df.unique('line_item_resource_id')\n",
    "unique_resources_df = unique_resources_df.sort('line_item_product_code')\n",
    "unique_resources_df.write_parquet('./non-null-resources.snappy.parquet', compression='snappy')\n",
    "unique_resources_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the filtering condition for EBS Volumes and EC2 Instances\n",
    "# filtered_df = unique_resources_df.filter(\n",
    "#     (pl.col('line_item_product_code').str.contains('EC2')) &\n",
    "#     (pl.col('line_item_resource_id').str.contains(r'i-')) |\n",
    "#     (pl.col('line_item_resource_id').str.contains(r'vol-'))\n",
    "# )\n",
    "\n",
    "# # Optionally, display the filtered DataFrame\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique AWS regions\n",
    "region_df = not_null_resources_df.select('product_region_code').unique()\n",
    "regions = region_df.to_dict().get('product_region_code')\n",
    "for r in regions:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe where each row is a resource arn, a tag name, and a tag value\n",
    "# there will be multiple rows for each resource arn if there are multiple tags\n",
    "triplets_dict = {\n",
    "        \"ResourceARN\": [],\n",
    "        \"TagKey\": [],\n",
    "        \"TagValue\": []\n",
    "    }\n",
    "\n",
    "\n",
    "tag_key = 'appNumber'\n",
    "tagged_resources = []\n",
    "for r in regions:\n",
    "    client = boto3.client('resourcegroupstaggingapi', region_name=r)\n",
    "    paginator = client.get_paginator('get_resources')\n",
    "    # response_iterator = paginator.paginate()\n",
    "\n",
    "    # paginator = client.get_resources()\n",
    "    # response_iterator = paginator.paginate()\n",
    "    response_iterator = paginator.paginate(\n",
    "    TagFilters=[\n",
    "        {\n",
    "            'Key': tag_key,\n",
    "            # 'Values': [\n",
    "            #     'app3',\n",
    "            #     'app2'\n",
    "            # ]\n",
    "        },\n",
    "    ],\n",
    "    #   ResourceTypeFilters=[\n",
    "    #     'ec2:instance',\n",
    "    # ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    for response in response_iterator:\n",
    "        for resource in response[\"ResourceTagMappingList\"]:\n",
    "            # print(resource[\"ResourceARN\"], resource[\"Tags\"])\n",
    "            for tag in resource[\"Tags\"]:\n",
    "                # skip null and empty values\n",
    "                if all([resource[\"ResourceARN\"], tag[\"Key\"], tag[\"Value\"]]):\n",
    "                    # print(resource[\"ResourceARN\"], tag[\"Key\"], tag[\"Value\"])\n",
    "                    if tag[\"Key\"] == tag_key:\n",
    "                        tagged_resources.extend(triplets_dict[\"ResourceARN\"])\n",
    "                        triplets_dict[\"ResourceARN\"].append(resource[\"ResourceARN\"])\n",
    "                        triplets_dict[\"TagKey\"].append(tag[\"Key\"])\n",
    "                        triplets_dict[\"TagValue\"].append(tag[\"Value\"])\n",
    "triplets_df = pl.DataFrame(triplets_dict)\n",
    "triplets_df = triplets_df.sort('TagKey')\n",
    "triplets_df = triplets_df.unique('ResourceARN')\n",
    "\n",
    "\n",
    "tagged_resources_set = set(tagged_resources)\n",
    "print(tagged_resources_set)\n",
    "print(len(tagged_resources_set))\n",
    "# triplets_df.write_parquet('./tag-data.snappy.parquet', compression='snappy')\n",
    "triplets_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe where each row is a resource arn, a tag name, and a tag value\n",
    "# there will be multiple rows for each resource arn if there are multiple tags\n",
    "triplets_dict = {\n",
    "        \"ResourceARN\": [],\n",
    "        \"TagKey\": [],\n",
    "        \"TagValue\": []\n",
    "    }\n",
    "\n",
    "for r in regions:\n",
    "    client = boto3.client('resourcegroupstaggingapi', region_name=r)\n",
    "    paginator = client.get_paginator('get_resources')\n",
    "    # response_iterator = paginator.paginate()\n",
    "\n",
    "    # paginator = client.get_resources()\n",
    "    response_iterator = paginator.paginate()\n",
    "    # response_iterator = paginator.paginate(ResourceTypeFilters=[\n",
    "    #     'ec2:instance',\n",
    "    # ])\n",
    "\n",
    "    for response in response_iterator:\n",
    "        for resource in response[\"ResourceTagMappingList\"]:\n",
    "            # print(resource[\"ResourceARN\"], resource[\"Tags\"])\n",
    "            for tag in resource[\"Tags\"]:\n",
    "                # skip null and empty values\n",
    "                if all([resource[\"ResourceARN\"], tag[\"Key\"], tag[\"Value\"]]):\n",
    "                    # print(resource[\"ResourceARN\"], tag[\"Key\"], tag[\"Value\"])\n",
    "                    triplets_dict[\"ResourceARN\"].append(resource[\"ResourceARN\"])\n",
    "                    triplets_dict[\"TagKey\"].append(tag[\"Key\"])\n",
    "                    triplets_dict[\"TagValue\"].append(tag[\"Value\"])\n",
    "triplets_df = pl.DataFrame(triplets_dict)\n",
    "triplets_df = triplets_df.sort('TagKey')\n",
    "\n",
    "triplets_df.write_parquet('./tag-data.snappy.parquet', compression='snappy')\n",
    "triplets_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "# Replace 'example.parquet' with the path to your local Parquet file for inspection\n",
    "table = pq.read_table('tag-data.snappy.parquet')\n",
    "\n",
    "# Extract and print schema\n",
    "schema = table.schema\n",
    "print(\"CREATE EXTERNAL TABLE IF NOT EXISTS cur_database.tag_data_table (\")\n",
    "for field in schema:\n",
    "    print(f\"  {field.name} {field.type},\")\n",
    "print(\")\")\n",
    "print(\"STORED AS PARQUET\")\n",
    "print(\"LOCATION 's3://curprocessorstack-curbucket1acad2a6-josrlebznwwi/quicksight/tag-data.snappy.parquet';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Compile the regex pattern once\n",
    "arn_regex = re.compile(\n",
    "    r\"^arn:\"\n",
    "    r\"(?P<partition>aws(-[a-z]+)?):\"\n",
    "    r\"(?P<service>[a-z0-9-]+):\"\n",
    "    r\"(?P<region>[a-z0-9-]*):\"\n",
    "    r\"(?P<account_id>[0-9]*):\"\n",
    "    r\"(?P<resource>.+)$\"\n",
    ")\n",
    "\n",
    "def is_arn(string):\n",
    "    \"\"\"Check if a string is an AWS ARN.\"\"\"\n",
    "    match = arn_regex.match(string)\n",
    "    return match is not None\n",
    "\n",
    "def reconstruct_arn(product_code: str, resource_id: str, account_id: str, region: str) -> str:\n",
    "    \"\"\"\n",
    "    Reconstructs an ARN for a given resource based on product code and resource ID.\n",
    "    \"\"\"\n",
    "    if is_arn(resource_id):\n",
    "        return resource_id\n",
    "    if product_code == 'AmazonEC2':\n",
    "        if resource_id.startswith('i-'):\n",
    "            return f\"arn:aws:ec2:{region}:{account_id}:instance/{resource_id}\"\n",
    "        elif resource_id.startswith('vol-'):\n",
    "            return f\"arn:aws:ec2:{region}:{account_id}:volume/{resource_id}\"\n",
    "        elif resource_id.startswith('snap-'):\n",
    "            return f\"arn:aws:ec2:{region}:{account_id}:snapshot/{resource_id}\"\n",
    "    elif product_code in {'AmazonRDS', 'rds'}:\n",
    "        if resource_id.startswith('db-'):\n",
    "            return f\"arn:aws:rds:{region}:{account_id}:db:{resource_id}\"\n",
    "    elif product_code == 'AmazonS3':\n",
    "        return f\"arn:aws:s3:::{resource_id}\"\n",
    "    elif product_code == 'AmazonDynamoDB':\n",
    "        return f\"arn:aws:dynamodb:{region}:{account_id}:table/{resource_id}\"\n",
    "    return f\"UnknownServiceType: {product_code} or Resource: {resource_id} not supported\"\n",
    "\n",
    "# Convert DataFrame to list of dictionaries\n",
    "resources_ids = unique_resources_df.to_dicts()\n",
    "\n",
    "# Placeholder for reconstructed ARNs\n",
    "reconstructed_resources = []\n",
    "\n",
    "# Loop through resources and reconstruct ARNs\n",
    "for resource in resources_ids:\n",
    "    resource_id = resource['line_item_resource_id']\n",
    "    product_code = resource['line_item_product_code']\n",
    "    region = resource['product_region_code']\n",
    "    account_id = resource['line_item_usage_account_id']\n",
    "    \n",
    "    reconstructed_arn = reconstruct_arn(product_code, resource_id, account_id, region)\n",
    "    resource['line_item_resource_id'] = reconstructed_arn\n",
    "    \n",
    "    # Append the modified resource back\n",
    "    reconstructed_resources.append(resource)\n",
    "\n",
    "# Convert the updated list of dictionaries back to a DataFrame\n",
    "updated_df = pl.DataFrame(reconstructed_resources)\n",
    "\n",
    "# Save the modified DataFrame to a Parquet file\n",
    "updated_df.write_parquet('./modified-unique-resources.snappy.parquet', compression='snappy')\n",
    "updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'example.parquet' with the path to your local Parquet file for inspection\n",
    "table = pq.read_table('modified-unique-resources.snappy.parquet')\n",
    "\n",
    "# Extract and print schema\n",
    "schema = table.schema\n",
    "print(\"CREATE EXTERNAL TABLE IF NOT EXISTS cur_database.modified_unique_resources_table (\")\n",
    "for field in schema:\n",
    "    print(f\"  {field.name} {field.type},\")\n",
    "print(\")\")\n",
    "print(\"STORED AS PARQUET\")\n",
    "print(\"LOCATION 's3://curprocessorstack-curbucket1acad2a6-josrlebznwwi/quicksight/modified-unique-resources/';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filtering condition for EBS Volumes and EC2 Instances\n",
    "filtered_df = updated_df.filter(\n",
    "    (pl.col('line_item_product_code').str.contains('EC2')) &\n",
    "    (pl.col('line_item_resource_id').str.contains(r'i-')) |\n",
    "    (pl.col('line_item_resource_id').str.contains(r'vol-'))\n",
    ")\n",
    "\n",
    "# Optionally, display the filtered DataFrame\n",
    "filtered_df\n",
    "\n",
    "# Save the filtered DataFrame to a Parquet file\n",
    "# filtered_df.write_parquet('./ebs-ec2-resources.snappy.parquet', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter1 = 0\n",
    "\n",
    "non_arns = []\n",
    "for r in resources_ids:\n",
    "    if not is_arn(r['line_item_resource_id']):\n",
    "        non_arns.append({'id': r['line_item_resource_id'], 'service': r['line_item_product_code']})\n",
    "        counter1 = counter1 + 1\n",
    "\n",
    "\n",
    "print(len(resources_ids))\n",
    "print(counter1)\n",
    "\n",
    "# Print results\"\n",
    "print(\"Number of Non-ARN Strings:\", len(non_arns))\n",
    "non_arns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'example.parquet' with the path to your local Parquet file for inspection\n",
    "table = pq.read_table('unique-resources.snappy.parquet')\n",
    "\n",
    "# Extract and print schema\n",
    "schema = table.schema\n",
    "print(\"CREATE EXTERNAL TABLE IF NOT EXISTS cur_database.unique_resources_table (\")\n",
    "for field in schema:\n",
    "    print(f\"  {field.name} {field.type},\")\n",
    "print(\")\")\n",
    "print(\"STORED AS PARQUET\")\n",
    "print(\"LOCATION 's3://curprocessorstack-curbucket1acad2a6-josrlebznwwi/quicksight/unique-resources.snappy.parquet';\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
